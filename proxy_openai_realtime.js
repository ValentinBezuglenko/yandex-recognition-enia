// npm install ws axios
import WebSocket, { WebSocketServer } from "ws";
import axios from "axios";

const PORT = process.env.PORT || 10000;
const OPENAI_KEY = process.env.OPENAI_API_KEY;

if (!OPENAI_KEY) throw new Error("OPENAI_API_KEY not set");

//
// === 1. Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Realtime-ÑĞµÑÑĞ¸Ğ¸ ===
//
async function createRealtimeSession() {
  const response = await axios.post(
    "https://api.openai.com/v1/realtime/sessions",
    { model: "gpt-4o-realtime-preview-2024-12-17" },
    {
      headers: {
        Authorization: `Bearer ${OPENAI_KEY}`,
        "Content-Type": "application/json",
      },
    }
  );
  return response.data;
}

//
// === 2. Ğ—Ğ°Ğ¿ÑƒÑĞº WS-ÑĞµÑ€Ğ²ĞµÑ€Ğ° ===
//
async function start() {
  console.log(`\nğŸš€ Proxy listening on ws://0.0.0.0:${PORT}`);
  if (process.env.RENDER_SERVICE_NAME) {
    console.log(
      `   WebSocket URL: wss://${process.env.RENDER_SERVICE_NAME}.onrender.com/ws`
    );
  }

  const wss = new WebSocketServer({ port: PORT, path: "/ws" });

  wss.on("connection", async (esp) => {
    console.log("âœ… ESP connected");
    console.log("ESP IP:", esp._socket.remoteAddress);

    try {
      //
      // === 3. Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Realtime-ÑĞµÑÑĞ¸Ñ ===
      //
      const session = await createRealtimeSession();
      const clientSecret =
        session?.client_secret?.value || session?.client_secret;
      if (!clientSecret)
        throw new Error("No client_secret in OpenAI response");

      const wsUrl = `wss://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-12-17&client_secret=${encodeURIComponent(
        clientSecret
      )}`;

      const oa = new WebSocket(wsUrl, {
        headers: {
          Authorization: `Bearer ${clientSecret}`,
          "OpenAI-Beta": "realtime=v1",
        },
      });

      //
      // === 4. ĞŸĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ñ ===
      //
      let ready = false;
      let audioBuffer = [];
      let flushTimer = null;
      const FLUSH_TIMEOUT = 2000; // 2 ÑĞµĞºÑƒĞ½Ğ´Ñ‹ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾Ñ â†’ flush

      //
      // === 5. Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ¸ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ğ½Ğ° OpenAI ===
      //
      function flushAudioBuffer() {
        if (audioBuffer.length === 0 || oa.readyState !== WebSocket.OPEN) return;

        const full = Buffer.concat(audioBuffer);
        const base64 = full.toString("base64");

        oa.send(
          JSON.stringify({
            type: "input_audio_buffer.append",
            audio: base64,
          })
        );

        console.log(`ğŸ“¤ Sent batch: ${audioBuffer.length} chunks (${full.length} bytes)`);

        audioBuffer = [];
        clearTimeout(flushTimer);
        flushTimer = null;
      }

      //
      // === 6. ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹ Ğ¾Ñ‚ OpenAI ===
      //
      oa.on("open", () => {
        console.log("ğŸ”— Connected to OpenAI Realtime");
      });

      oa.on("message", (data) => {
        try {
          const parsed = JSON.parse(data.toString());

          if (parsed.type === "session.created") {
            console.log("ğŸŸ¢ OpenAI session ready");
            ready = true;
          }

          if (parsed.type === "response.output_text.delta") {
            process.stdout.write(parsed.delta); // Ğ±ĞµĞ· Ğ¿ĞµÑ€ĞµĞ½Ğ¾ÑĞ° ÑÑ‚Ñ€Ğ¾ĞºĞ¸
          }

          if (parsed.type === "response.completed") {
            console.log("\nâœ… Transcription complete\n");
          }

          if (parsed.type === "error") {
            console.error("âŒ OpenAI Error:", parsed.error);
          }
        } catch (err) {
          console.error("âš ï¸ Parse error:", err.message);
        }
      });

      oa.on("close", () => console.log("ğŸ”Œ OpenAI closed"));
      oa.on("error", (e) => console.error("âŒ OpenAI WS Error:", e.message));

      //
      // === 7. ĞŸÑ€Ğ¸Ñ‘Ğ¼ PCM Ğ¾Ñ‚ ESP ===
      //
      esp.on("message", (msg) => {
        if (Buffer.isBuffer(msg)) {
          console.log(`ğŸ§ Got ${msg.length} bytes from ESP`);

          audioBuffer.push(msg);

          // Ğ¡Ğ±Ñ€Ğ°ÑÑ‹Ğ²Ğ°ĞµĞ¼ Ñ‚Ğ°Ğ¹Ğ¼ĞµÑ€ Ğ¸ ÑÑ‚Ğ°Ğ²Ğ¸Ğ¼ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ½Ğ° 2 ÑĞµĞºÑƒĞ½Ğ´Ñ‹
          clearTimeout(flushTimer);
          flushTimer = setTimeout(() => {
            console.log("â³ 2s timeout â€” flushing buffer");
            flushAudioBuffer();
          }, FLUSH_TIMEOUT);

          return;
        }

        const text = msg.toString().trim();

        if (text.includes("STREAM_STOPPED") || text.includes("STREAM STOPPED")) {
          console.log("ğŸ›‘ Stream stopped â€” committing buffer");
          flushAudioBuffer();

          setTimeout(() => {
            oa.send(JSON.stringify({ type: "input_audio_buffer.commit" }));
            oa.send(JSON.stringify({
              type: "response.create",
              response: {
                modalities: ["text"],
                instructions: "Return only the raw transcription of the spoken audio.",
              },
            }));
            console.log("ğŸ“¨ Sent commit + response.create");
          }, 300);
        }

        if (text.includes("STREAM_STARTED") || text.includes("STREAM STARTED")) {
          console.log("ğŸ™ Stream started");
          audioBuffer = [];
          clearTimeout(flushTimer);
        }
      });

      esp.on("close", () => {
        console.log("ğŸ”Œ ESP disconnected");
        oa.close();
      });

      esp.on("error", (e) => console.error("âŒ ESP error:", e.message));
    } catch (err) {
      console.error("âŒ Setup error:", err.message);
      if (esp.readyState === WebSocket.OPEN) esp.close();
    }
  });
}

start().catch(console.error);
