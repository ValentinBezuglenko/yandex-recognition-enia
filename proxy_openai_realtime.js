// === server.js ===
// Ğ Ğ°Ğ±Ğ¾Ñ‡Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ: ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑĞµÑ‚ RAW Ğ¸ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ¸Ñ€ÑƒĞµÑ‚ Ñ‡ĞµÑ€ĞµĞ· OpenAI
// Ğ—Ğ°Ğ¿ÑƒÑĞº: node server.js
// Ğ¢Ñ€ĞµĞ±ÑƒĞµÑ‚: npm install ws axios

import fs from "fs";
import path from "path";
import WebSocket, { WebSocketServer } from "ws";
import axios from "axios";

const PORT = process.env.PORT || 8765;
const OPENAI_KEY = process.env.OPENAI_API_KEY;

if (!OPENAI_KEY) throw new Error("OPENAI_API_KEY not set");

// === ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° Ğ¿Ğ°Ğ¿ĞºĞ¸ Ğ´Ğ»Ñ Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹ ===
const recordingsDir = path.resolve("recordings");
if (!fs.existsSync(recordingsDir)) fs.mkdirSync(recordingsDir);

// === Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ OpenAI Realtime ÑĞµÑÑĞ¸Ñ ===
async function createRealtimeSession() {
  const r = await axios.post(
    "https://api.openai.com/v1/realtime/sessions",
    {
      model: "gpt-4o-realtime-preview-2024-12-17",
      voice: "alloy",
    },
    {
      headers: {
        Authorization: `Bearer ${OPENAI_KEY}`,
        "Content-Type": "application/json",
      },
    }
  );
  return r.data;
}

// === Ğ—Ğ°Ğ¿ÑƒÑĞº WebSocket-Ğ¿Ñ€Ğ¾ĞºÑĞ¸ ===
async function start() {
  console.log(`\nğŸš€ Proxy listening on ws://0.0.0.0:${PORT}`);
  const wss = new WebSocketServer({ port: PORT, path: "/ws" });

  wss.on("connection", async (esp) => {
    console.log("âœ… ESP connected");
    console.log("ESP IP:", esp._socket.remoteAddress);

    // ĞŸĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ´Ğ»Ñ Ğ·Ğ°Ğ¿Ğ¸ÑĞ¸
    let rawFilePath = "";
    let rawStream = null;
    let totalBytes = 0;
    let session = null;

    try {
      // Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ realtime-ÑĞµÑÑĞ¸Ñ OpenAI
      session = await createRealtimeSession();
      const clientSecret =
        session?.client_secret?.value || session?.client_secret;

      const oa = new WebSocket(
        `wss://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-12-17&client_secret=${encodeURIComponent(
          clientSecret
        )}`,
        {
          headers: {
            Authorization: `Bearer ${clientSecret}`,
            "OpenAI-Beta": "realtime=v1",
          },
        }
      );

      oa.on("open", () => console.log("ğŸ”— Connected to OpenAI Realtime"));
      oa.on("message", (data) => {
        try {
          const msg = JSON.parse(data.toString());
          if (msg.type === "session.created")
            console.log("ğŸŸ¢ OpenAI session ready");
          else if (msg.type === "error")
            console.error("âŒ OpenAI Error:", msg.error);
        } catch (err) {
          console.error("âš ï¸ JSON parse error:", err.message);
        }
      });

      // === ĞŸÑ€Ğ¸Ñ‘Ğ¼ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¾Ñ‚ ESP ===
      esp.on("message", async (msg) => {
        if (Buffer.isBuffer(msg)) {
          if (rawStream) {
            rawStream.write(msg);
            totalBytes += msg.length;
          }
          return;
        }

        const text = msg.toString().trim();

        if (text.includes("STREAM STARTED")) {
          const timestamp = new Date().toISOString().replace(/[:.]/g, "-");
          rawFilePath = path.join(
            recordingsDir,
            `session_${timestamp}.raw`
          );
          rawStream = fs.createWriteStream(rawFilePath);
          totalBytes = 0;
          console.log(`ğŸ™ Recording raw audio to: ${rawFilePath}`);
        }

        if (text.includes("STREAM STOPPED")) {
          if (rawStream) {
            rawStream.end(() => {
              console.log(
                `ğŸ’¾ Recording closed (${(totalBytes / 1024).toFixed(1)} KB)`
              );
            });
            rawStream = null;

            // ĞŸĞ¾ÑĞ»Ğµ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ¸ Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ (Ğ½ĞµĞ¾Ğ±ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾) ÑĞ´ĞµĞ»Ğ°Ñ‚ÑŒ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ Ğ½Ğ° Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ğ¸Ñ
            if (fs.existsSync(rawFilePath)) {
              console.log("ğŸ§  Sending for transcription...");
              try {
                const audioData = fs.readFileSync(rawFilePath);
                const base64 = audioData.toString("base64");

                oa.send(
                  JSON.stringify({
                    type: "input_audio_buffer.append",
                    audio: base64,
                  })
                );
                oa.send(JSON.stringify({ type: "input_audio_buffer.commit" }));
                oa.send(
                  JSON.stringify({
                    type: "response.create",
                    response: {
                      modalities: ["text"],
                      instructions:
                        "Transcribe and briefly summarize the recorded audio.",
                    },
                  })
                );

                console.log("ğŸ“¨ Sent for OpenAI transcription");
              } catch (err) {
                console.error("âŒ Transcription send error:", err.message);
              }
            }
          }
        }
      });

      esp.on("close", () => {
        console.log("ğŸ”Œ ESP disconnected");
        if (rawStream) rawStream.end();
        oa.close();
      });
    } catch (err) {
      console.error("âŒ Setup error:", err.message);
      if (esp.readyState === WebSocket.OPEN) esp.close();
    }
  });
}

start().catch(console.error);
